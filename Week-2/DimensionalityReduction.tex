\section{Dimensionality Reduction}

Dimensionality reduction is the process of reducing the number of random variables under consideration in a statistical analysis.

What Dimensionality Reduction basically means is that we start off with a set of variables, say 20, and then by the end of the process we have a smaller number but which still reflect a large proportion of the information contained in
the original dataset. The way that the ``information contained" is measured is by considering the variability within
and co-variation across variables, that is the variance and co-variance (i.e. correlation). Either the reduction might
be by discovering that a particular linear combination of the independent variables accounts for a large percentage of the total variability in the data or by discovering that several of the variables reflect another \textbf{\textit{latent variable}} (i.e. unobserved variable)


\textbf{Variable Selection Procedures}(also known in Data Science as ``Feature selection") are used to find an optimal subset of the original variables to best fit the data. This reduces the effect of multicollinearity and overfitting. In these methods, independent variables are either used or not used ,but no transformation of the data takes place.

%-----------------------------------------%

\subsection{Principal Component Analysis}
Other types of procedures, such as principal component analysis and factor analysis, will transform the data.
Principal component analysis (PCA) is a mathematical procedure that uses an \textbf{orthogonal transformation} to convert a set of observations of possibly correlated independent variables into a set of values of artificial linearly uncorrelated variables called \textbf{principal components} (also called Factors in factor analysis). These principal components are used to represent the latent variables.

(Orthogonal transformation is a Linear Algebra technique. It is not required to know it. Orthogonality can be crudely described as a synomym for perpendicularity. If two variables are orthogonal, they are essential uncorrelated.)

The number of principal components is less than or equal to the number of original variables. This transformation is defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible), and each succeeding component in turn has the highest variance possible under the constraint that it be orthogonal to (i.e., uncorrelated with) the preceding components.

%-----------------------------------------%

\subsection{Factor Analysis}
Factor analysis is a collection of methods used to examine how underlying latent variables influence the
responses on a number of measured variables.
There are basically two types of factor analysis: exploratory and confirmatory.
\begin{itemize}
\item Exploratory factor analysis (EFA) attempts to discover the nature of the latent variables influencing
a set of responses.
\item Confirmatory factor analysis (CFA) tests whether a specified set of latent variables is influencing responses in a predicted way.
\end{itemize}
(We are principally concerned with EFA, and hence will mean that type when discussing FA).


%-----------------------------------------%
\subsection{Factor Analysis vs. Principal Component Analysis}
Exploratory factor analysis is often confused with principal component analysis (PCA), a similar
statistical procedure. However, there are significant differences between the two: FA and PCA
will provide somewhat different results when applied to the same data.
\begin{itemize}
\item Principal components analysis involves extracting linear composites of observed variables. Factor analysis is based on a formal model predicting observed variables from theoretical latent factors.

\item The purpose of PCA is to derive a relatively small number of components that can account for the
variability found in a relatively large number of measures. This procedure, called dimensionality reduction, is
typically performed when you don't want to include all of the original measures in analyses
but still want to work with the information that they contain.

\item The first difference is that the direction of
influence is reversed: FA assumes that the measured responses are based on the underlying factors
while in PCA the principal components are based on the measured responses.

\item The second difference is that with Principal Components Analysis, the goal is to account for as much of the total variance in the variables as possible. The objective in Factor Analysis is to explain the covariances or correlations among the variables. (FA assumes that the variance in the measured variables can be decomposed into that accounted for by common factors and that accounted for by unique factors. The principal components are defined simply as linear combinations of the measurements, and so will contain both common and
    unique variance.)

\item In summary, you should use FA when you are interested in making statements about the factors that
are responsible for a set of observed responses, and you should use PCA when you are simply interested
in performing data reduction.
\end{itemize}

In a nut-shell
\begin{itemize}
\item Use Principal Components Analysis to reduce the data into a smaller number of components.
\item Use Factor Analysis to understand what latent variables are structured in the data \textbf{structure detection} .
\end{itemize}
